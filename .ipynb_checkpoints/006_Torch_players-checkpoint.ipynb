{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "55e8dd61-a1b5-44ff-a7fd-215d3c6bdee2",
   "metadata": {},
   "source": [
    "# Crear un TorchPlayer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e8578ae-4e1f-482b-9113-c273bdc35f8c",
   "metadata": {},
   "source": [
    "Recibe el modelo a instanciar como path y juega con el mismo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d709faf-8879-4ddd-95f9-4a5ee0e5b74e",
   "metadata": {},
   "source": [
    "- Pensar como resolver el problema de que solo samplee las válidas\n",
    "- Agregarle la opción de monte carlo tree search (opcional) con las opciones de iterationLimit, timeLimit\n",
    "\n",
    "Si va a agregar MCTS mirar la notebook 007_MCTS.ipnb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9e64bb32",
   "metadata": {},
   "outputs": [],
   "source": [
    "from boardgame2 import ReversiEnv\n",
    "import numpy as np\n",
    "from players import RandomPlayer, DictPolicyPlayer, GreedyPlayer\n",
    "from multi_env import make_reversi_vec_env, SelfPlayEnv\n",
    "import torch as th\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.policies import ActorCriticPolicy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "84f5c470-4dc9-4be9-8222-6c7df3b97e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TorchPlayer():\n",
    "    # \n",
    "    def __init__(self, model_path=None, player=1, board_shape=None, env=None, deterministic=True, only_valid=True, mcts=False, iterationLimit=None, timeLimit=None, flatten_action=False):\n",
    "        if model_path is None:\n",
    "            model_path = './models/Reversi_PPO_8by8_0.99_0.95_0.0_10_6_masked_actions/best_model.zip'\n",
    "        self.model = PPO.load(model_path)\n",
    "        self.player = player\n",
    "        self.flatten_action = flatten_action\n",
    "        if (env is None) and (board_shape is None):\n",
    "            print(\"board_shape and env can't be both None\")\n",
    "        if env is None:\n",
    "            self.env = self.model.env\n",
    "        if board_shape is None:\n",
    "            self.board_shape = env.board_shape\n",
    "        else:\n",
    "            self.board_shape = board_shape\n",
    "        \n",
    "    def predict(self, board):\n",
    "        board = board * self.player\n",
    "        board_reshape = board[np.newaxis,:,:]\n",
    "        action = self.model.predict(board_reshape)[0]\n",
    "        if self.flatten_action:\n",
    "            return action\n",
    "        else:\n",
    "            return [action // self.board_shape, action % self.board_shape]\n",
    "        return action"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfaf25a3-f5a2-4bdc-8086-f5507a7f8fd0",
   "metadata": {},
   "source": [
    "# Arena"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5acfcf1e-8c56-4448-91ef-45a6a3f5d3de",
   "metadata": {},
   "source": [
    "Testear el jugador contra los distintos jugadores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9cf645d6-1761-4bf4-9380-a1344e0b7f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def arena_stats(Player_1, Player_2, board_shape, N=500):\n",
    "    \n",
    "    env = ReversiEnv(board_shape=board_shape)\n",
    "    wins_as_first = 0\n",
    "    wins_as_second = 0\n",
    "    plays_as_first = 0\n",
    "    plays_as_second = 0\n",
    "    total_steps = 0\n",
    "    player_1 = Player_1(player=1, board_shape=board_shape, flatten_action=False)\n",
    "    player_2 = Player_2(player=-1, board_shape=board_shape, flatten_action=False)\n",
    "    for i in range(N):\n",
    "        # Aveces empieza un jugador, a veces el otro\n",
    "        first_player = np.random.choice([-1, 1])\n",
    "        player_1.player = first_player\n",
    "        player_2.player = -first_player\n",
    "        \n",
    "        plays_as_first = plays_as_first + (first_player == 1)\n",
    "        plays_as_second = plays_as_second + (first_player == -1)\n",
    "        \n",
    "        done = False\n",
    "        n_steps = 0\n",
    "        (board, player) = env.reset()\n",
    "        \n",
    "        while not done:\n",
    "            if first_player == player:\n",
    "                action = player_1.predict(board=board) \n",
    "            else:\n",
    "                action = player_2.predict(board=board)\n",
    "            (board, player), reward, done, info = env.step(action)\n",
    "            n_steps = n_steps + 1\n",
    "        total_steps = total_steps + n_steps\n",
    "        wins_as_first = wins_as_first + (reward == first_player) * (first_player == 1)\n",
    "        wins_as_second = wins_as_second + (reward == first_player) * (first_player == -1)\n",
    "    print(f'Wins as first: {wins_as_first/plays_as_first}')\n",
    "    print(f'Wins as second: {wins_as_second/plays_as_second}')\n",
    "    print(f'Plays as first: {plays_as_first}')\n",
    "    print(f'Plays as second: {plays_as_second}')\n",
    "    print(f'Avg game duration: {total_steps/N}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aafb7761",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wins as first: 0.688298918387414\n",
      "Wins as second: 0.7049847405900305\n",
      "Plays as first: 1017\n",
      "Plays as second: 983\n",
      "Avg game duration: 59.7395\n"
     ]
    }
   ],
   "source": [
    "arena_stats(TorchPlayer, GreedyPlayer, 8, N=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1cbd4f3-8347-4237-b410-85a9d0d0d8bc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
