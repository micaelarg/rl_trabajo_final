{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "75725f40-2c8a-4b23-bbba-4dac40c93b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3700508d-a5d0-44c1-8653-ffe2c9a8e922",
   "metadata": {},
   "outputs": [],
   "source": [
    "from boardgame2 import ReversiEnv\n",
    "from dynamic_programming import generate_uniform_stochastic_policy, policy_evaluation, stochastic_policy_eval_step, generate_deterministic_policy, deterministic_policy_eval_step\n",
    "from tree_search import bfs_cannonical\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6626624-c808-4080-be16-a7b65e33755a",
   "metadata": {},
   "source": [
    "# Programación dinámica"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6bdf619-3c94-4d88-aa61-92e620995d4d",
   "metadata": {},
   "source": [
    "En esta parte no es necesario la implementación de código ya que ya esta todo resuelto. Si tiene que responder algunas preguntas en **EDX**.\n",
    "\n",
    "Si lo desea puede ver el código para analizar la implementación, pero es opcional\n",
    "\n",
    "Si quiere profundizar le recomendamos mirar:\n",
    "\n",
    "- bfs_cannonical cannonical de la librería tree_search\n",
    "- policy_evaluation, policy_improve, policy_iterartion y value_iteration de dynamic_programming"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eae6c89-099e-4478-a9de-497e3ba485e8",
   "metadata": {},
   "source": [
    "### La idea de esta sección es generar las $V^*(s)$y $\\Pi^*(s)$ (óptimas) en 4x4 para poder hacer los análisis posteriores\n",
    "### Por eso se deben correr todas las celdas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07d19023-07a9-4dd0-9a0c-14d0eed1a1fa",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d663898a-15f8-445a-af04-3fa178c6c4ca",
   "metadata": {},
   "source": [
    "# Busqueda de todos los estados canónicos\n",
    "\n",
    "Solo desde el punto de vista del jugador +1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a561791-2438-4746-afd2-ba0ed877f9e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 54 s, sys: 4.05 s, total: 58 s\n",
      "Wall time: 53.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "board_size = 4\n",
    "states = bfs_cannonical(board_size, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5afc6482-b962-48b8-bf4e-17eee0f9fd35",
   "metadata": {},
   "source": [
    "Al ser canónico, no es necesario que el jugador sea parte del estado ya que siempre se puede pensar como que le toca jugar al jugador +1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c28c09c5-2a9f-4bb5-9bf7-45975a63e736",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0, 0, 0, 0, 1, -1, 0, 0, -1, 1, 0, 0, 0, 0, 0)\n",
      "(0, 0, -1, 0, 0, -1, -1, 0, 0, 1, -1, 0, 0, 0, 0, 0)\n",
      "(0, 0, 0, 0, 0, -1, -1, -1, 0, 1, -1, 0, 0, 0, 0, 0)\n",
      "(0, 0, 0, 0, 0, -1, 1, 0, -1, -1, -1, 0, 0, 0, 0, 0)\n",
      "(0, 0, 0, 0, 0, -1, 1, 0, 0, -1, -1, 0, 0, -1, 0, 0)\n"
     ]
    }
   ],
   "source": [
    "# Listamos los primeros 5 estados encontrados\n",
    "for s in list(states.keys())[0:5]:\n",
    "    print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e3a9854f-8307-41a4-b1cc-f05bc0642466",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardamos el estado s0\n",
    "s0 = list(states.keys())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fae829c1-77da-48e1-a732-58334c1a2ada",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 0, 0, 0, 0, 1, -1, 0, 0, -1, 1, 0, 0, 0, 0, 0)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dbf7152c-20ab-4990-afaa-ed0ffdc768b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  0,  0,  0],\n",
       "       [ 0,  1, -1,  0],\n",
       "       [ 0, -1,  1,  0],\n",
       "       [ 0,  0,  0,  0]], dtype=int8)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mostrado como tablero\n",
    "np.array(s0).reshape(4,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "beeac3f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#EDX pto1: \n",
    "s_tp = (1, 1, 1, -1, 0, 1, 1, 0, 0, -1, 1, 1, 0, 0, 0, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d61f5bb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acción: (2, 0)\n",
      "{'done': False, 'winner': -0.0, 'next_node': (-1, -1, -1, 1, 0, -1, -1, 0, -1, -1, -1, -1, 0, 0, 0, 0)}\n",
      "acción: (3, 0)\n",
      "{'done': True, 'winner': -1, 'next_node': (-1, -1, -1, 1, 0, -1, -1, 0, 0, -1, -1, -1, -1, 0, 0, 0)}\n",
      "acción: (3, 1)\n",
      "{'done': False, 'winner': -0.0, 'next_node': (-1, -1, -1, 1, 0, -1, -1, 0, 0, -1, -1, -1, 0, -1, 0, 0)}\n"
     ]
    }
   ],
   "source": [
    "#EDX pto1: \n",
    "for action, next_data in states[s_tp].items():\n",
    "    print(f'acción: {action}')\n",
    "    print(next_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "601082ff-abe4-46b0-8124-6664c18c51c3",
   "metadata": {},
   "source": [
    "Cada estado se guarda con todas sus posibles acciones y dado el estado y la acción, se guarda:\n",
    "- **next_node**: el próximo estado al ejecutar esa acción\n",
    "- **done**: si termina el juego (episodio)\n",
    "- **winner**: si al ejecutar la acción alguno de los dos jugadores gana: (+1 o -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "447da39b-0540-408e-952c-ccf4de7a2359",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acción: (0, 2)\n",
      "{'done': False, 'winner': -0.0, 'next_node': (0, 0, -1, 0, 0, -1, -1, 0, 0, 1, -1, 0, 0, 0, 0, 0)}\n",
      "acción: (1, 3)\n",
      "{'done': False, 'winner': -0.0, 'next_node': (0, 0, 0, 0, 0, -1, -1, -1, 0, 1, -1, 0, 0, 0, 0, 0)}\n",
      "acción: (2, 0)\n",
      "{'done': False, 'winner': -0.0, 'next_node': (0, 0, 0, 0, 0, -1, 1, 0, -1, -1, -1, 0, 0, 0, 0, 0)}\n",
      "acción: (3, 1)\n",
      "{'done': False, 'winner': -0.0, 'next_node': (0, 0, 0, 0, 0, -1, 1, 0, 0, -1, -1, 0, 0, -1, 0, 0)}\n"
     ]
    }
   ],
   "source": [
    "for action, next_data in states[s0].items():\n",
    "    print(f'acción: {action}')\n",
    "    print(next_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e301b4e1-e976-4f5e-8ac4-c23f9ddbb31d",
   "metadata": {},
   "source": [
    "# Ejemplo de un estado terminal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6b3e34dc-95ae-4946-8fb1-98e1a3334db2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, -1, -1, -1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0)\n",
      "acción: (-1, 0)\n",
      "{'done': True, 'winner': 1, 'next_node': (0, 1, 1, 1, 0, -1, -1, 0, -1, -1, -1, 0, 0, 0, 0, 0)}\n",
      "\n",
      "(0, 0, 0, -1, 0, 1, 1, -1, 0, 1, 1, -1, 0, 1, 0, 0)\n",
      "acción: (-1, 0)\n",
      "{'done': True, 'winner': 1, 'next_node': (0, 0, 0, 1, 0, -1, -1, 1, 0, -1, -1, 1, 0, -1, 0, 0)}\n",
      "\n",
      "(0, 0, 1, 0, -1, 1, 1, 0, -1, 1, 1, 0, -1, 0, 0, 0)\n",
      "acción: (-1, 0)\n",
      "{'done': True, 'winner': 1, 'next_node': (0, 0, -1, 0, 1, -1, -1, 0, 1, -1, -1, 0, 1, 0, 0, 0)}\n",
      "\n",
      "(0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, -1, -1, -1, 0)\n",
      "acción: (-1, 0)\n",
      "{'done': True, 'winner': 1, 'next_node': (0, 0, 0, 0, 0, -1, -1, -1, 0, -1, -1, 0, 1, 1, 1, 0)}\n",
      "\n",
      "(-1, -1, -1, 1, 0, -1, -1, 0, 0, 1, -1, -1, 0, 0, 0, 0)\n",
      "acción: (-1, 0)\n",
      "{'done': True, 'winner': 1, 'next_node': (1, 1, 1, -1, 0, 1, 1, 0, 0, -1, 1, 1, 0, 0, 0, 0)}\n",
      "\n",
      "(-1, -1, -1, 0, -1, -1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0)\n",
      "acción: (-1, 0)\n",
      "{'done': True, 'winner': 1, 'next_node': (1, 1, 1, 0, 1, 1, -1, 0, 0, -1, -1, -1, 0, 0, 0, 0)}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "done = 0\n",
    "for s in states.keys():\n",
    "    for action, next_data in states[s].items():\n",
    "        if next_data['done']:\n",
    "            print(s)\n",
    "            print(f'acción: {action}')\n",
    "            print(next_data)\n",
    "            done = done + 1\n",
    "            print()\n",
    "            break\n",
    "    if done > 5:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62806c5b-8982-431b-acd9-1d6d2e46c934",
   "metadata": {},
   "source": [
    "La acción (-1, 0) es la acción PASS. En principio solo se ejecuta si no hay opciones válidas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d3979263-db5d-4b37-8cd4-359a04644903",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(-1, 0): {'done': True,\n",
       "  'winner': 1,\n",
       "  'next_node': (1, 1, 1, 0, 1, 1, -1, 0, 0, -1, -1, -1, 0, 0, 0, 0)}}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "states[(-1, -1, -1, 0, -1, -1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "051fbae2-641e-4c52-bcde-170cf96e86a5",
   "metadata": {},
   "source": [
    "# Policy Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac42e57b-692a-4df7-a9dc-54c3729d0d93",
   "metadata": {},
   "source": [
    "### Politica estocástica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "33c4d35b-1e1d-4505-ae26-ea63f04b42cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "stochastic_pi = generate_uniform_stochastic_policy(states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cc278a4b-e187-456c-88dc-61664c2fea86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(0, 2): 0.25, (1, 3): 0.25, (2, 0): 0.25, (3, 1): 0.25}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ejemplos\n",
    "stochastic_pi[(0, 0, 0, 0, 0, 1, -1, 0, 0, -1, 1, 0, 0, 0, 0, 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "96bb08f4-03c2-4714-abad-b64dc5f3ff80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(0, 1): 0.3333333333333333,\n",
       " (0, 3): 0.3333333333333333,\n",
       " (2, 3): 0.3333333333333333}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stochastic_pi[(0, 0, -1, 0, 0, -1, -1, 0, 0, 1, -1, 0, 0, 0, 0, 0)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae5999b0-78fa-4745-a7d3-ca25192fa39c",
   "metadata": {},
   "source": [
    "Esto genera una política con distribución uniforme que luego será evaluada usuando **policy evaluation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5b26d10d-b7a3-47a2-a6f3-b88c7459f598",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration number:  1 2 3 4 5 6 7 8 9 10 11 12 13 \n"
     ]
    }
   ],
   "source": [
    "V_stochastic, iters = policy_evaluation(stochastic_policy_eval_step, \n",
    "                             states, \n",
    "                             stochastic_pi, 1e-8, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3326e48-c8d4-475d-82ea-7c788765c870",
   "metadata": {},
   "source": [
    "#### Ejemplos de la V luego de converger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8530667a-01de-4d72-8131-623f48e31685",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.2403001935859148"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "V_stochastic[(0, 0, 0, 0, 0, 1, -1, 0, 0, -1, 1, 0, 0, 0, 0, 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a520fe00-b246-4d76-a39e-fe0ead3bb601",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2403001935859148"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "V_stochastic[(0, 0, -1, 0, 0, -1, -1, 0, 0, 1, -1, 0, 0, 0, 0, 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4f0c923d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EDX pto2:\n",
    "st_2 = (0, 0, -1, 0, 0, -1, -1, 0, 0, 1, -1, 0, 0, 0, 0, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a5f129bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(0, 1): 0.3333333333333333,\n",
       " (0, 3): 0.3333333333333333,\n",
       " (2, 3): 0.3333333333333333}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# EDX pto2:\n",
    "stochastic_pi[st_2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f372be8-8c59-4733-85b4-330315814478",
   "metadata": {},
   "source": [
    "### Política determinística"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "521a0c17-4af1-4bb6-8121-c61c52c280fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "det_pi = generate_deterministic_policy(states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5100a747-3333-4344-9de1-852e17c52a04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 2)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "det_pi[(0, 0, 0, 0, 0, 1, -1, 0, 0, -1, 1, 0, 0, 0, 0, 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b4c97a74-8398-43cb-9dd7-9b085ab66064",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 3)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "det_pi[(0, 0, -1, 0, 0, -1, -1, 0, 0, 1, -1, 0, 0, 0, 0, 0)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daeb4f44-2315-4f74-b23d-d0df51894a8b",
   "metadata": {},
   "source": [
    "Notar que ahora la política dado el estado tiene solo una acción posible que se construyó de manera arbitraria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "101b1089-b9eb-421e-95a6-13d2a8fb62ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration number:  1 2 3 4 5 6 7 8 9 10 11 12 13 \n"
     ]
    }
   ],
   "source": [
    "# Run it multiple times to check it takes different number of iterations to converge\n",
    "V_det, _ = policy_evaluation(deterministic_policy_eval_step, \n",
    "                             states, \n",
    "                             det_pi, 1e-8, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b864354-cefc-424a-bcae-7d32bc50bc5f",
   "metadata": {},
   "source": [
    "#### Ejemplos de la V luego de converger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "426b8f04-bedf-4d6f-b15f-d91449d0423a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "V_det[(0, 0, 0, 0, 0, 1, -1, 0, 0, -1, 1, 0, 0, 0, 0, 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9fdc2f72-512a-4e7f-bdea-eefee263a572",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "V_det[(0, 0, -1, 0, 0, -1, -1, 0, 0, 1, -1, 0, 0, 0, 0, 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "64f7856d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{-1, 0, 1}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# EDX pto3:\n",
    "est_det = []\n",
    "for i in states:\n",
    "    est_det.append(V_det[i])\n",
    "set(est_det)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbca6f6b-944b-4c08-9452-be8b65dc673a",
   "metadata": {},
   "source": [
    "# Policy Iteration\n",
    "\n",
    "Partiendo de cualquier política (estocástica o determinística), por medio de Policy Iteration se puede obtener las óptimas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fbf2950c-8947-44f0-89e7-f2ce9f81ad65",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dynamic_programming import policy_improve, policy_iteration, generate_deterministic_policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2db6733e-eb0d-4a33-a531-4684e74bae90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration number:  1 2 3 4 5 6 7 8 9 10 11 12 \n",
      "Number of differences of new policy vs old policy: 12481\n",
      "---------------------------\n",
      "Iteration number:  1 2 3 4 5 6 7 8 9 10 11 12 \n",
      "Number of differences of new policy vs old policy: 1919\n",
      "---------------------------\n",
      "Iteration number:  1 2 3 4 5 6 7 8 9 10 11 12 \n",
      "Number of differences of new policy vs old policy: 516\n",
      "---------------------------\n",
      "Iteration number:  1 2 3 4 5 6 7 8 9 10 11 12 13 \n",
      "Number of differences of new policy vs old policy: 125\n",
      "---------------------------\n",
      "Iteration number:  1 2 3 4 5 6 7 8 9 10 11 12 13 \n",
      "Number of differences of new policy vs old policy: 30\n",
      "---------------------------\n",
      "Iteration number:  1 2 3 4 5 6 7 8 9 10 11 12 13 \n",
      "Number of differences of new policy vs old policy: 8\n",
      "---------------------------\n",
      "Iteration number:  1 2 3 4 5 6 7 8 9 10 11 12 13 \n",
      "Number of differences of new policy vs old policy: 4\n",
      "---------------------------\n",
      "Iteration number:  1 2 3 4 5 6 7 8 9 10 11 12 13 \n",
      "Number of differences of new policy vs old policy: 2\n",
      "---------------------------\n",
      "Iteration number:  1 2 3 4 5 6 7 8 9 10 11 12 13 \n",
      "Number of differences of new policy vs old policy: 1\n",
      "---------------------------\n",
      "Iteration number:  1 2 3 4 5 6 7 8 9 10 11 12 13 \n",
      "Number of differences of new policy vs old policy: 0\n",
      "---------------------------\n",
      "CPU times: user 15.7 s, sys: 164 ms, total: 15.8 s\n",
      "Wall time: 15.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "initial_policy = generate_deterministic_policy(states)\n",
    "optimum_policy, optimum_V = policy_iteration(states, initial_policy, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "36d741f6-1aba-4263-9c06-253fc77447aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('mdp/pi_mdp', optimum_policy)\n",
    "np.save('mdp/v_mdp', optimum_V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1361e0c2-2b2e-4393-95ab-13152147fdfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 3)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimum_policy[(0, 0, -1, 0, 0, -1, -1, 0, 0, 1, -1, 0, 0, 0, 0, 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d133ef7e-d058-4f93-a71c-b2aba2015791",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimum_V[(0, 0, -1, 0, 0, -1, -1, 0, 0, 1, -1, 0, 0, 0, 0, 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "005257ff-d1b9-43e0-a3d0-6b2659834ab9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  0, -1,  0],\n",
       "       [ 0, -1, -1,  0],\n",
       "       [ 0,  1, -1,  0],\n",
       "       [ 0,  0,  0,  0]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array((0, 0, -1, 0, 0, -1, -1, 0, 0, 1, -1, 0, 0, 0, 0, 0)).reshape(4, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cb700bfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# EDX pto 4:\n",
    "optimum_V[(0, 0, -1, 0, 0, -1, -1, 0, 0, 1, -1, 0, 0, 0, 0, 0)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32444a3b-b383-41e8-b0ae-1978b70965dc",
   "metadata": {},
   "source": [
    "# Value Iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5895e877-5331-42b3-b21c-651c3ccf9e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dynamic_programming import value_iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4e0c40c2-db8d-4368-86b7-af9f8413ec66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 16 2.148329015302604\n",
      "2 14 1.3984082309742596\n",
      "3 14 0.7103688654451921\n",
      "4 13 0.3661814318465639\n",
      "5 12 0.1380402974781458\n",
      "6 11 0.05770628692848223\n",
      "7 10 0.02005554416506682\n",
      "8 8 0.006710033363777003\n",
      "9 6 0.0023857896404540454\n",
      "10 6 0.0005964474101135114\n",
      "11 6 0.00011183388939628339\n",
      "12 0 0.0\n",
      "CPU times: user 4.67 s, sys: 0 ns, total: 4.67 s\n",
      "Wall time: 4.67 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "V, delta = value_iteration(states, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bbc6918",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
